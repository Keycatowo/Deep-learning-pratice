{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEd6JBRWTp4l"
   },
   "source": [
    "# Softmax回歸\n",
    "softmax回歸是一個線性多分類回歸的模型  \n",
    "實際上softmax回歸是從Logistic回歸模型轉化來的,但Logistic是二分類,而Softmax是多分類模型   \n",
    "\n",
    "## Softmax function\n",
    "**主要目的**: 將各類別的\"評分\"轉換成合理的機率值  \n",
    "例如:$score=(a,b,c)$,經過了softmax之後就會變成$({e^a\\over{e^a+e^b+e^c}},{e^b\\over{e^a+e^b+e^c}},{e^a\\over{e^a+e^b+e^c}})$\n",
    "假設$x$是單一樣本的特徵,而$W,b$是Softmax模型的參數  \n",
    "  + $x$:輸入圖片,784維vector\n",
    "  + $Ｗ$:矩陣,大小為784*10\n",
    "  + $b$:10維vector\n",
    "\n",
    "$$Logit={W\\bf}^Tx+b$$\n",
    "Logit一樣是一個10-D的vector,可以看做樣本對於各類別的評分,然後再用Softmax來轉換成機率值$$y=Softmax(Logit)$$ 即$$y=Softmax({W\\bf}^Tx+b)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBwcLodeavmD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "y6RxDTUoazus",
    "outputId": "e28ebd47-435a-4c94-c30d-697583ca7134"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1011 22:15:15.824826  5876 deprecation.py:323] From <ipython-input-2-b74a0447c961>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W1011 22:15:15.827823  5876 deprecation.py:323] From A:\\Anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W1011 22:15:15.860764  5876 deprecation.py:323] From A:\\Anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1011 22:15:16.378972  5876 deprecation.py:323] From A:\\Anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W1011 22:15:16.391599  5876 deprecation.py:323] From A:\\Anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W1011 22:15:16.514266  5876 deprecation.py:323] From A:\\Anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ow9SPltpbSgT"
   },
   "outputs": [],
   "source": [
    "# Build x\n",
    "## x 是一個預留位置(placeholder),代表待識別的圖片\n",
    "x = tf.placeholder(tf.float32, [None,784])\n",
    "\n",
    "# W是Softmax模型中的倉鼠,將784-D輸入轉換成10-D輸出\n",
    "## Tensorflow中模型的參數用tf.Variable表示\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# y表示模型的輸出,y_表示實際的影像標籤\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U6vld3hAeM_n"
   },
   "source": [
    "## Tensor\n",
    "上面的程式碼定義了一些**預留位置(placeholder)**和**變數(Variable)**,而在TensorFlow中,這些東西實際上都是**Tensor**  \n",
    "在Tensorflow中的Tensor並不是實際的數值，而且一些我們「希望」Tensorflow計算的**節點**  \n",
    "\n",
    "### placeholder (預留位置) Tensor\n",
    "不用依賴其他的Tensor，是由使用者自行傳遞值給Tensorflow，一般是用來儲存樣本資料和標籤。  \n",
    "例如這邊的`x = tf.placeholder(tf.float32,[None,784])`是用來儲存訓練圖片的，而其中的`[None,784]`表示形狀，**None**表示這個維度的大小任意，即我們可以傳遞任意張圖片給這個預留位置，而每張圖片則是用一個784維的資料來表示。  \n",
    "\n",
    "### variabl (變數) Tensor\n",
    "變數是在計算過程中可以改變的值，每次計算以後變數的值都會被儲存下來，通常用來儲存模型的參數。  \n",
    "例如這邊的`W = tf.Variable(tf.zeros([784,10]))`和`b = tf.Variable(tf.zeros([10]))`都是Softmax模型的參數。  \n",
    "因為建立變數的時候通常需要初始值，所以這邊設W為一個784\\*10的零矩陣，而b則一個10維的零向量。  \n",
    "\n",
    "### 其他\n",
    "除了前面提到的兩個Tensor，這邊還用了`y = tf.nn.softmax(tf.matmul(x,W)+b)`，這裡的y就是一個依賴x,W,b的Tensor。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CrossEntropy loss\n",
    "模型的輸出是`y`，而實際的標籤是`y_`，我們會希望他們越相似越好  \n",
    "而在Softmax迴歸中，通常會用CrossEntropy的損失來衡量這種相似程度，而損失越小則表示模型的輸出和實際的情況越接近。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = \\\n",
    "    tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最佳化loss\n",
    "有了loss，就可以用梯度下降法來針對模型參數<strong>W</strong>和<strong>b</strong>來最佳化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用梯度下降法對模型參數最佳化\n",
    "# GradientDescentOptimizer後面接的0.01是模型的學習率(Learning Rate)\n",
    "train_step = \\\n",
    "    tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 預設會針對所有變數計算梯度，這邊只定義了兩個變數<strong>W</strong>和<strong>b</strong>,所以程式會使用梯度下降法對<strong>W</strong>和<strong>b</strong>計算梯度並更新他們的值。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session(階段)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一個Session，只有在session中才能執行最佳化步驟train_step\n",
    "sess = tf.InteractiveSession()\n",
    "# 執行之前必須初始化所有變數、分配記憶體\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果說*Tensor*是**希望**Tensorflow計算的節點  \n",
    "那*Session*就是對這些節點進行計算的**上下文**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 進行1000步梯度下降\n",
    "# 每次使用100個資料\n",
    "for i in range (1000):\n",
    "    # 在mnist.train中取100個資料的batch\n",
    "    # batch_xs,batch_ys的形狀: (100,784)和(100,10)\n",
    "    # batch_xs,batch_ys對應的placeholder: x,y_\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    # 在Session中執行train_step\n",
    "    # 執行的時候傳入placeholder的值\n",
    "    sess.run(train_step,\n",
    "             feed_dict={\n",
    "                 x:  batch_xs,\n",
    "                 y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Session裡面不需要計算placeholder的值，而是直接把placeholder的值傳給Session  \n",
    "和Variable不一樣，placeholder的值不會被儲存，每次可以傳遞不同的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "# 檢驗模型訓練的結果\n",
    "\n",
    "# 正確的預測結果\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), \n",
    "                              tf.argmax(y_,1)) # tf.argmax(...,1)是用來取出array中最大值的index\n",
    "# 計算準確率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,\n",
    "                                  tf.float32)) # tf.cast(...,float32)可以用來轉換變數的型態成float32格式\n",
    "# 在Session中執行Tensor可以獲得Tensor的值\n",
    "# 這邊取得最後模型的準確率\n",
    "print(sess.run(accuracy,\n",
    "               feed_dict={\n",
    "                   x:mnist.test.images,\n",
    "                   y_:mnist.test.labels\n",
    "               }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.argmax(y, 1)`將預測出來最大的那個機率的index取出來  \n",
    "`tf.argmax(y_,1)`將轉成one-hot表示的那一個位置的index取出  \n",
    "然後用`tf.equal()`比較二者是否相等  \n",
    "最後用`tf.reduce_mean()`計算相等比例(因為相等為1，不相等為0，所以平均即為準確率)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST (tensorflow).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
